# ğŸ“° Dynamic RAG News Chatbot (Ollama + GNews)

A **Dynamic Retrieval-Augmented Generation (RAG) chatbot** that answers user questions using **live news data** from the **GNews API** and generates responses using a **local LLM via Ollama**.  
The system is fully containerized using **Docker Compose** and requires **no OpenAI API key**.

This project was built as part of a hackathon to demonstrate:
- Real-time data ingestion
- Dynamic knowledge retrieval
- Local LLM inference
- Cloud-ready deployment

---

## ğŸš€ What This Project Does

- Fetches **latest news in real time** using the GNews API
- Builds dynamic context from live articles
- Uses **Ollama (LLaMA 3.2)** to generate answers
- Responds instantly without re-indexing or restarting
- Runs fully inside Docker containers
- Exposes a clean REST API using FastAPI

---

## ğŸ§  Architecture Overview
User Query

â†“

FastAPI (/ask endpoint)

â†“

Fetch live news (GNews API)

â†“

Dynamic prompt construction (RAG)

â†“

Ollama (LLaMA 3.2)

â†“

AI-generated response


---

## ğŸ§± Tech Stack

- FastAPI
- Python
- Ollama (LLaMA 3.2)
- GNews API
- Docker & Docker Compose

---

## ğŸ“ Project Structure

dynamic-rag-chatbot/

â”‚

â”œâ”€â”€ app.py # FastAPI application

â”œâ”€â”€ Dockerfile # Builds the ragbot container

â”œâ”€â”€ docker-compose.yml # Runs Ollama + ragbot

â”œâ”€â”€ requirements.txt # Python dependencies

â”œâ”€â”€ .env # Environment variables (ignored by Git)

â”œâ”€â”€ .gitignore # Git ignore rules

â””â”€â”€ README.md # Project documentation

---

ğŸ”‘ How to Get GNews API Key

1. Visit https://gnews.io
2. Sign up for a free account
3. Copy your API key
4. Paste it into the .env file

---
## ğŸ³ Docker Setup
Build and start the application
docker compose up -d --build

Verify running containers
docker compose ps

Expected services:
* ollama
* pathway-ragbot

---
## ğŸ¤– Pull the Model (First Time Only)
docker exec -it ollama ollama pull llama3.2

Verify model:
docker exec -it ollama ollama list

---
## ğŸ§ª API Endpoints
Health Check
GET /health

Example:
curl http://localhost:8000/health

Response:
{"ok": true}

Ask a Question
GET /ask?q=YOUR_QUESTION

Example (curl):
curl -G "http://localhost:8000/ask" \
  --data-urlencode "q=What is trending in the news today?"

Example (browser):
http://localhost:8000/ask?q=What%20is%20trending%20in%20the%20news%20today

Response:
{
  "question": "What is trending in the news today",
  "answer": "Based on the latest headlines...",
  "source": "GNews + Ollama"
}

---
## ğŸŒ GitHub Codespaces Usage

When running in GitHub Codespaces, open Port 8000 and use:
https://<codespace-name>-8000.app.github.dev/ask?q=Your%20question

Example:
https://silver-potato-xxxx-8000.app.github.dev/ask?q=What%20is%20trending%20in%20the%20news%20today

---
## ğŸ›  Common Issues & Fixes
### Internal Server Error
* Check logs:
docker compose logs ragbot
* Verify GNews API key
* Ensure Ollama is running
* Ensure model is pulled

### GNews API Errors
* Ensure query is URL-encoded
* Free plan has rate limits

### Ollama Not Responding
* Confirm container is running
* Verify correct model name
* Check /api/generate endpoint

---
## ğŸ Hackathon Checklist

 âœ” Live data ingestion
 
 âœ” Dynamic RAG pipeline
 
 âœ” Local LLM (no OpenAI)
 
 âœ” Dockerized deployment
 
 âœ” API-based interface
 
 âœ” Shareable demo URL

---
## ğŸ“Œ Future Enhancements

* Add vector database
* Add streaming responses
* Add web UI
* Add article citations
* Add multi-language support

---
## ğŸ‘¨â€ğŸ’» Authors

This project was built as a **team hackathon project** by:

- Aditya  
- Soumyaranjan  
- Virinchy  

Dynamic RAG News Chatbot â€“ Hackathon Project
